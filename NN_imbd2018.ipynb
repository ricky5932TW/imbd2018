{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN5lvJiPHTSx"
      },
      "source": [
        "匯入套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "--0dKXjIHaHT"
      },
      "outputs": [],
      "source": [
        "import os  \n",
        "import xlrd\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH2POeOHHchg"
      },
      "source": [
        "載入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyCqqqocGxJ0",
        "outputId": "70c14d16-49f7-4e08-ead4-12f2d11d8d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20160419000_2016419_10450.xls\n",
            "20160419001_2016419_114348.xls\n",
            "20160419002_2016419_132916.xls\n",
            "20160422004_2016422_17837.xls\n",
            "20160425002_2016425_104626.xls\n",
            "20160425009_2016425_19220.xls\n",
            "20160428011_2016428_191949.xls\n",
            "20160429000_2016429_84549.xls\n",
            "20160429002_2016429_104511.xls\n",
            "20160429004_2016429_14936.xls\n",
            "20160419003_2016419_143535.xls\n",
            "20160419004_2016419_153453.xls\n",
            "20160419005_2016419_164411.xls\n",
            "20160421002_2016421_171815.xls\n",
            "20160421003_2016421_182129.xls\n",
            "20160422001_2016422_95822.xls\n",
            "20160422002_2016422_111140.xls\n",
            "20160422003_2016422_161044.xls\n",
            "20160425001_2016425_94440.xls\n",
            "20160425003_2016425_11527.xls\n",
            "20160425004_2016425_131231.xls\n",
            "20160425005_2016425_161517.xls\n",
            "20160425008_2016425_175644.xls\n",
            "20160426000_2016426_93632.xls\n",
            "20160426001_2016426_104437.xls\n",
            "20160426002_2016426_115725.xls\n",
            "20160426004_2016426_165510.xls\n",
            "20160426005_2016426_18652.xls\n",
            "20160427001_2016427_14570.xls\n",
            "20160427002_2016427_16045.xls\n",
            "20160427003_2016427_17747.xls\n",
            "20160427004_2016427_1871.xls\n",
            "20160428001_2016428_8419.xls\n",
            "20160428002_2016428_10314.xls\n",
            "20160428003_2016428_11622.xls\n",
            "20160428004_2016428_12638.xls\n",
            "20160428005_2016428_131728.xls\n",
            "20160428007_2016428_15325.xls\n",
            "20160428008_2016428_161338.xls\n",
            "20160428010_2016428_181928.xls\n",
            "20160429001_2016429_94620.xls\n",
            "20160429003_2016429_11447.xls\n",
            "20160519001_2016519_145215.xls\n",
            "20160519002_2016519_155127.xls\n",
            "20160519003_2016519_16513.xls\n",
            "20160520000_2016520_105518.xls\n",
            "20160520001_2016520_161526.xls\n",
            "20160523000_2016523_112052.xls\n",
            "20160523001_2016523_132720.xls\n",
            "20160523002_2016523_142635.xls\n",
            "[0.4328]\n",
            "torch.Size([40, 7500])\n",
            "torch.Size([40, 1])\n",
            "torch.Size([10, 7500])\n",
            "torch.Size([10, 1])\n",
            "n_feature= 7500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ricky\\AppData\\Local\\Temp\\ipykernel_13108\\4276018000.py:122: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  error.append(float(num))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  100 | Train Loss: 0.042692504823207855 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  200 | Train Loss: 0.042692504823207855 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  300 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  400 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  500 | Train Loss: 0.042692504823207855 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  600 | Train Loss: 0.042692504823207855 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  700 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  800 | Train Loss: 0.042692504823207855 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  900 | Train Loss: 0.042692508548498154 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  1000 | Train Loss: 0.042692508548498154 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "END\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Parent directory /content/drive/My Drive/Colab Notebooks/imbd2018 does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 131\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m'\u001b[39m\u001b[33mEND\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m#torch.save(net,'/content/drive/My Drive/IMDB/CNC_tcim_20180715.pkl')\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/content/drive/My Drive/Colab Notebooks/imbd2018/CNC_tcim_20180715.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# NN4------------------------------------------------------------\u001b[39;00m\n\u001b[32m    135\u001b[39m \n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m#net = torch.load('/content/drive/My Drive/IMDB/CNC_tcim_20180715.pkl')\u001b[39;00m\n\u001b[32m    137\u001b[39m net = torch.load(\u001b[33m'\u001b[39m\u001b[33m/content/drive/My Drive/Colab Notebooks/imbd2018/CNC_tcim_20180715.pkl\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\serialization.py:943\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    940\u001b[39m _check_save_filelike(f)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    944\u001b[39m         _save(\n\u001b[32m    945\u001b[39m             obj,\n\u001b[32m    946\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    949\u001b[39m             _disable_byteorder_record,\n\u001b[32m    950\u001b[39m         )\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\serialization.py:810\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    809\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\serialization.py:781\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    777\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    778\u001b[39m         torch._C.PyTorchFileWriter(\u001b[38;5;28mself\u001b[39m.file_stream, _compute_crc32)\n\u001b[32m    779\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compute_crc32\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[31mRuntimeError\u001b[39m: Parent directory /content/drive/My Drive/Colab Notebooks/imbd2018 does not exist."
          ]
        }
      ],
      "source": [
        "#test_path = 'test_10/'\n",
        "test_path = 'test_10/'\n",
        "#train_path = 'train_40/'\n",
        "train_path = 'train_40/'\n",
        "\n",
        "data_Spindle_X = []\n",
        "data_Spindle_Y = []\n",
        "data_Workbench_X = []\n",
        "data_Workbench_Y = []\n",
        "data_label = []\n",
        "\n",
        "test_Spindle_X = []\n",
        "test_Spindle_Y = []\n",
        "test_Workbench_X = []\n",
        "test_Workbench_Y = []\n",
        "test_label = []\n",
        "         \n",
        "def getData(file_path):\n",
        "        \n",
        "        workbook = xlrd.open_workbook(file_path)\n",
        "        sheet = workbook.sheets()[0]\n",
        "\n",
        "        sheet_data = {\n",
        "                'Spindle_X':[],\n",
        "                'Spindle_Y':[],\n",
        "                'Workbench_X':[], \n",
        "                'Workbench_Y':[]\n",
        "        }\n",
        "        \n",
        "        for i in range(7500):\n",
        "                sheet_data['Spindle_X'].append(sheet.cell(i,0).value)\n",
        "                sheet_data['Spindle_Y'].append(sheet.cell(i,1).value)\n",
        "                sheet_data['Workbench_X'].append(sheet.cell(i,2).value)\n",
        "                sheet_data['Workbench_Y'].append(sheet.cell(i,3).value)\n",
        "\t\n",
        "\n",
        "        if 'test' in file_path:\n",
        "          test_Spindle_X.append(sheet_data['Spindle_X'])\n",
        "          test_Spindle_Y.append(sheet_data['Spindle_Y'])\n",
        "          test_Workbench_X.append(sheet_data['Workbench_X'])\n",
        "          test_Workbench_Y.append(sheet_data['Workbench_Y'])\n",
        "          test_label.append([float(sheet.cell(7500,0).value[3:])])\n",
        "        else:\n",
        "          data_Spindle_X.append(sheet_data['Spindle_X'])\n",
        "          data_Spindle_Y.append(sheet_data['Spindle_Y'])\n",
        "          data_Workbench_X.append(sheet_data['Workbench_X'])\n",
        "          data_Workbench_Y.append(sheet_data['Workbench_Y'])\n",
        "          data_label.append([float(sheet.cell(7500,0).value[3:])])\n",
        "\n",
        "for file_name in os.listdir(test_path):\n",
        "        print(file_name)\n",
        "        getData(test_path+file_name)\n",
        "\n",
        "for file_name in os.listdir(train_path):\n",
        "        print(file_name)\n",
        "        getData(train_path+file_name)\n",
        "\n",
        "#RNN2\n",
        "\n",
        "trainX = torch.tensor(data_Spindle_X)\n",
        "trainY = torch.tensor(data_label)\n",
        "\n",
        "print(data_label[0])\n",
        "print(trainX.size())\n",
        "print(trainY.size())\n",
        "\n",
        "testX = torch.tensor(test_Spindle_X)\n",
        "testY = torch.tensor(test_label)\n",
        "\n",
        "print(testX.size())\n",
        "print(testY.size())\n",
        "\n",
        "\n",
        "# NN3------------------------------------------------------------\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_feature, n_hidden, n_output):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
        "        self.hidden_1 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
        "        self.hidden_2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
        "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
        "        \n",
        "        x = F.relu(self.hidden_1(x))\n",
        "        x = F.relu(self.hidden_2(x))\n",
        "        \n",
        "        x = self.predict(x)             # linear output\n",
        "        return x\n",
        "\n",
        "net = Net(n_feature=len(trainX[0]), n_hidden=256, n_output=1)     # define the network\n",
        "print('n_feature=',len(trainX[0]))\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.045)\n",
        "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
        "\n",
        "all_error = []\n",
        "\n",
        "for t in range(1,1001):\n",
        "    prediction = net(trainX)     # input x and predict based on x\n",
        "    #print 'prediction',prediction,'trainY',trainY\n",
        "    loss = loss_func(prediction, trainY)     # must be (1. nn output, 2. target)\n",
        "    #print loss\n",
        "    optimizer.zero_grad()   # clear gradients for next train\n",
        "    loss.backward()         # backpropagation, compute gradients\n",
        "    optimizer.step()        # apply gradients\n",
        "\n",
        "    if t % 100 == 0:\n",
        "        \n",
        "        k = prediction.data.numpy()\n",
        "        ans = trainY.numpy()\n",
        "        real = []\n",
        "        right = []\n",
        "        error = []\n",
        "        count = 0.0\n",
        "        for i in range(len(ans)):\n",
        "            num = abs(ans[i][0] - k[i][0]) / ans[i]\n",
        "            real.append(ans[i][0])\n",
        "            right.append(k[i][0])\n",
        "            error.append(float(num))\n",
        "            if num < 0.1:\n",
        "                count = count + 1.0\n",
        "        print('Epoch: ',t,'| Train Loss:',float(loss.data.numpy()),'| Acc:',(count / len(ans)) * 100,'%')\n",
        "        all_error.append(error)\n",
        "        print('==========================================================')\n",
        "\n",
        "print ('END')\n",
        "#torch.save(net,'/content/drive/My Drive/IMDB/CNC_tcim_20180715.pkl')\n",
        "torch.save(net,'/content/drive/My Drive/Colab Notebooks/imbd2018/CNC_tcim_20180715.pkl')\n",
        "\n",
        "\n",
        "# NN4------------------------------------------------------------\n",
        "\n",
        "#net = torch.load('/content/drive/My Drive/IMDB/CNC_tcim_20180715.pkl')\n",
        "net = torch.load('/content/drive/My Drive/Colab Notebooks/imbd2018/CNC_tcim_20180715.pkl')\n",
        "prediction = net(testX)     # input x and predict based on x\n",
        "\n",
        "loss = loss_func(prediction, testY)     # must be (1. nn output, 2. target)\n",
        "print(loss.data.numpy())\n",
        "k = prediction.data.numpy()\n",
        "ans = testY.numpy()\n",
        "real = []\n",
        "right = []\n",
        "error = []\n",
        "count = 0.0\n",
        "for i in range(len(ans)):\n",
        "    num = abs(ans[i][0] - k[i][0]) / ans[i]\n",
        "    real.append(ans[i][0])\n",
        "    right.append(round(k[i][0],8))\n",
        "    error.append(round(float(num),4))\n",
        "    if num < 0.1:\n",
        "        count = count + 1.0\n",
        "print('ans',real)\n",
        "print('test',right)\n",
        "print('error',error)\n",
        "print((count / len(ans)) * 100,'%')\n",
        "print('===========================')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
